%We look at some resent research published with regards to automatic NDS data reduction as well as some notable work in improving disparity maps and object detection in traffic scenes. 

%In \cite{Guo20133}, statistics from near-crashes and crashes are used to identify factors related to driver associated risks, such as age, experience, gender, and demographic. Similar studies are conducted in \cite{SimonsMorton2011587}, where results show that near-crash and crash percentage among teenagers were 75 \% lower in the presence of adult passengers and 96 \% higher among teenagers with risky friends. In \cite{mcevoy2006impact} NDS are used to quantify distracting activities from e.g. a mobile phones, which result in loss of concentration. Results show that drivers in average are engaged in distracting activity every 6 minutes, something which could result in a near-crash or crash.



In \cite{raviLaneSemantics}, monocular computer vision and information from the CAN bus is used to automatically detect 23 drive events, including lane position, vehicle localization within lanes, vehicle speed, traffic density, and road curvature. In \cite{raviOvertaking}, a system is developed for automatic labeling of driver behavior events relying on overtaking and receding vehicle detection. This type of system is categorized as Looking-In and Looking-Out (LiLo), which is discussed in depth in \cite{trivedi2007looking}. LiLo fits well with using multiple inputs to understand the driver's behavior. \\%An example of Looking-In is \cite{ohn2013driver} where driver behavior with respect to hand activity is evaluated.\\

%In \cite{SivaramanSurvey}, a review of the research conducted since 2005 in both monocular and stereo vision with respect to vision-based vehicle detection is presented. 
%Before 2005, \cite{bebisReview} conducted a review of on-road vehicle detection. Most of the research published with regard to vehicle detection is evaluating the methods on data, representing a limited part of the challenges. 

\cite{HirschmullerRLandSGBM} introduced the accurate and efficient Semi-Global Matching (SGM) algorithm from finding stereo correspondence. SGM make use of epipolar geometry, and in most cases a set of rectified stereo images. Horizontal lines in the images are used as a scan lines, matches are then found for all possible disparities in a 1D disparity search. A match for a pixel in the left image is found in the right image by searching through the corresponding horizontal row and locating the most similar block to a reference block around the original pixel in the left image. The offset between these pixels is known as the disparity, which, if correctly matched, is directly related to the distance to the corresponding object. A final match it based on the outcome of a smoothed path cost which is calculated in a number of directions for each disparity. In the same paper, the LR-RL-consistency check is proposed for reducing noise in the calculated disparity image. \\

In \cite{labayrade2003onboard}, the so-called V-disparity is generated and used for separating objects from the ground/road surface. The V-disparity examines the vertical coordinates in a (u,v) image coordinate system and is constructed using a disparity map from, e.g. the SGM algorithm. What is especially histograms are calculated for each row in the disparity. Significant surfaces in the disparity map will then show up as lines in the V-disparity. %\cite{labayrade2003onboard} is evaluated on nighttime conditions. 

%In \cite{daimler6DVision}, 6D-vision is introduced, where features are found in the left monocular image and then located in 3D by using the stereo images. For each feature point, a Kalman filter is used to estimate a 6D vector consisting of the 3D position and 3D motion vector. \cite{daimler6DVision} is able to do ego-motion compensation by identifying the static 6D points. The predicted static world points are then compared to the remaining points to isolate the ego-motion. In \cite{daimlerStixel}, this work is continued and by using 6D-vision, tracked feature points are represented as stixels, which is a vertical areas of equal disparity. The tracked objects are being classified using prior knowledge of vehicle shapes. Alternatively, objects can be classified using clustering in the disparity map, as seen in \cite{broggiTerramax}. In \cite{adverseWeatherDaimlar,exploitedTrafficSceneStatistics}, temporal and scene priors from good conditions are used with the purpose of improving the disparity map in adverse weather conditions, such as night, rain, and snow. Using these priors, the object detection rate improves on a database of 3000 frames including bad weather while reducing the false positive rate.
%\vspace{2pt}